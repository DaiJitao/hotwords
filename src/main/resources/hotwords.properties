hdfs.stopwords=hdfs://amend/hotwordNer/file/stopwords.txt
# stopwords=F:/intell_workspace/hotwords/src/main/resources/stopwords.txt
stopwords=/data/appRun/hotwordjava/data/stopwords.txt
# 0 代表内部语料库；1代表外部语料库,对应着idf_corpus_file文件
idf_corpus_type=0
idf_corpus_file=

# kafka配置
# 反序列
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
# 序列化
key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer
# kafka热词配置
hotwords.bootstrap.servers=10.121.17.193:9092,10.121.17.194:9092,10.121.17.195:9092
hotwords.group.id=1238
hotwords.enable.auto.commit=false
hotwords.auto.commit.interval.ms=1000
hotwords.max.poll.records=1000
hotwords.session.timeout.ms=30000
# latest
hotwords.auto.offset.reset=earliest

hotwords.topic.name=hotwords_test
# hadoop
fs.defaultFS=hdfs://amend
dfs.nameservices=amend
dfs.ha.namenodes.amend=carbigdata4,carbigdata5
dfs.namenode.rpc-address.amend.carbigdata4=carbigdata4:9000
# risbig15:9000
dfs.namenode.rpc-address.amend.carbigdata5=carbigdata5:9000
dfs.client.failover.proxy.provider.amend=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
# 任务目录 #   /hotwords_v1/tempDir/
tempDir=/hotwordNer/tempDir/
# /hotwordNer/taskDir  /hotwords_v1/taskDir/
taskDir=/hotwordNer/taskDir/